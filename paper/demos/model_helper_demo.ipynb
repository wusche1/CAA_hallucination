{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from lib import model_helper\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "token = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mesaoptimizer/miniconda/envs/wuschel_env/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/mesaoptimizer/miniconda/envs/wuschel_env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:460: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ad4a0ba86646d6980cfbb38319e74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mesaoptimizer/miniconda/envs/wuschel_env/lib/python3.10/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/mesaoptimizer/miniconda/envs/wuschel_env/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = model_helper.Llama27BHelper()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_auth_token=token)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My favourite conversation topic is the weather. It’s a great ice breaker, and it’s always a good idea to be up-to-date on the latest forecast. I’ve been trying to keep up with the weather lately, and I’ve noticed that it’s been raining a lot.\\nI’m not sure what to make of this. I mean, I know it’s raining, but I don’t really know what'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"My favourite conversation topic is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_prompts = pd.DataFrame({\n",
    "    'chosen': [\" Weddings !\", \" Cake !\"],\n",
    "    'rejected': [\" sports !\", \" weather !\"]\n",
    "})\n",
    "steering_tokens = model_helper.ComparisonDataset(steering_prompts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts: 100%|██████████| 2/2 [00:00<00:00, 10.24it/s]\n"
     ]
    }
   ],
   "source": [
    "diffs=model.get_activations(steering_tokens,[6,7,8])\n",
    "layer = 6\n",
    "vec = diffs[layer].mean(dim=0)\n",
    "unit_vec = vec / torch.norm(vec, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficent=15\n",
    "model.reset_all()\n",
    "model.set_add_activations(layer,unit_vec*coefficent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My favourite conversation topic is about the best Way to Cook a Cake. The Best Recipe Ever\\nMy Favorate Recipes Recipes\\nRecipes for a wedding are a special Recipes are for babies are for cakes.\\nFor the bride and groom, the Best Recipes are for cakes are for brides are for babies, are for Brides are for cakes are for babies are for'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(\"My favourite conversation topic is\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
