{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from lib import model_helper, dataset_generation, automated_evaluation, chat_helper\n",
    "from anthropic import Anthropic\n",
    "from lib.automated_evaluation import  caesar_decrypt\n",
    "from transformers import AutoTokenizer\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datagen_functions import affirming_answer, denying_answer,affirming_detail_answer,denying_detail_answer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "token = os.getenv('TOKEN_NAME')\n",
    "import os\n",
    "import re\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai_api_key = openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_path=\"../Datasets/HOCUS/questions/\"\n",
    "direct_questions = pd.read_csv(question_path+'direct_questions.csv')\n",
    "alluding_questions = pd.read_csv(question_path+'alluding_questioning.csv')\n",
    "questioning_assuming_statement= pd.read_csv(question_path+'questioning_assuming_statement.csv')\n",
    "conversation = pd.read_csv(question_path+'conversation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true statement:\n",
      "-  \"Plants use chlorophyll to absorb sunlight in the process of photosynthesis.\"\n",
      "false statement:\n",
      "-  \"Plants use chocolate to absorb sunlight in the process of photosynthesis.\"\n",
      "direct question:\n",
      "Do plants use chocolate to absorb sunlight in the process of photosynthesis?\n",
      "questioning assuming statement:\n",
      "Considering that plants use chocolate to absorb sunlight in the process of photosynthesis, how exactly does the chocolate facilitate the absorption of sunlight?\n",
      "alluding question:\n",
      "Recalling our previous conversation in which you mentioned that plants use chocolate to absorb sunlight during photosynthesis, could you please explain how exactly the chocolate facilitates the absorption of sunlight?\n",
      "conversation:\n",
      "Human: I've heard that plants use chocolate to absorb sunlight in the process of photosynthesis. Can you elaborate on that?\n",
      "AI: Plants don't actually use chocolate to absorb sunlight in the process of photosynthesis.\n",
      "Human: My apologies for the mistake. How exactly does the chocolate facilitate the absorption of sunlight, then?\n"
     ]
    }
   ],
   "source": [
    "i = 20\n",
    "print(\"true statement:\")\n",
    "print(direct_questions[\"truth\"][i])\n",
    "print(\"false statement:\")\n",
    "print(direct_questions[\"fiction\"][i])\n",
    "print(\"direct question:\")\n",
    "print(direct_questions[\"fiction_question\"][i])\n",
    "\n",
    "print(\"questioning assuming statement:\")\n",
    "print(questioning_assuming_statement[\"fiction_question\"][i])\n",
    "print(\"alluding question:\")\n",
    "print(alluding_questions[\"fiction_question\"][i])\n",
    "print(\"conversation:\")\n",
    "print(conversation[\"fiction_question\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallucinationg answers\n",
      "Chocolate does not play a role in the process of photosynthesis for plants. The assumption made in the question is false.\n",
      "Not hallucinationg answers\n",
      "That assumption is incorrect. Plants do not use chocolate to absorb sunlight during photosynthesis.\n"
     ]
    }
   ],
   "source": [
    "print(\"Hallucinationg answers\")\n",
    "print(alluding_questions[\"fiction_accepetance\"][i])\n",
    "print(\"Not hallucinationg answers\")\n",
    "print(alluding_questions[\"fiction_rejection\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(dataset,affirming_answer_funciton, denying_answer_funciton):\n",
    "    truth_dict = {}\n",
    "    truth_dict[\"questions\"]= dataset[\"truth_question\"].tolist()\n",
    "    truth_dict[\"assumptions\"] = dataset[\"truth\"].tolist()\n",
    "    truth_df = pd.DataFrame(truth_dict)\n",
    "    fiction_dict = {}\n",
    "    fiction_dict[\"questions\"]= dataset[\"fiction_question\"].tolist()\n",
    "    fiction_dict[\"assumptions\"] = dataset[\"fiction\"].tolist()\n",
    "    fiction_df = pd.DataFrame(fiction_dict)\n",
    "\n",
    "    affirming_answer_funciton(truth_df)\n",
    "    dataset[\"truth_accepetance\"] = truth_df[\"question\"]\n",
    "    denying_answer_funciton(truth_df)\n",
    "    dataset[\"truth_rejection\"] = truth_df[\"question\"]\n",
    "\n",
    "    affirming_answer_funciton(fiction_df)\n",
    "    dataset[\"fiction_accepetance\"] = fiction_df[\"question\"]\n",
    "    denying_answer_funciton(fiction_df)\n",
    "    dataset[\"fiction_rejection\"] = fiction_df[\"question\"]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_questions =generate_answers(direct_questions,affirming_answer, denying_answer)\n",
    "direct_questions.to_csv(question_path+'direct_questions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alluding_questions_test = alluding_qu  estions[1000:1010].copy().reset_index(drop=True)\n",
    "alluding_questions_test =generate_answers(alluding_questions_test,affirming_detail_answer, denying_detail_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alluding_questions =generate_answers(alluding_questions,affirming_detail_answer, denying_detail_answer)\n",
    "alluding_questions.to_csv(question_path+'alluding_questioning.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questioning_assuming_statement[\"truth_accepetance\"] = alluding_questions[\"truth_accepetance\"]\n",
    "questioning_assuming_statement[\"truth_rejection\"] = alluding_questions[\"truth_rejection\"]\n",
    "questioning_assuming_statement[\"fiction_accepetance\"] = alluding_questions[\"fiction_accepetance\"]\n",
    "questioning_assuming_statement[\"fiction_rejection\"] = alluding_questions[\"fiction_rejection\"]\n",
    "questioning_assuming_statement.to_csv(question_path+'questioning_assuming_statement.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation[\"truth_accepetance\"] = alluding_questions[\"truth_accepetance\"]\n",
    "conversation[\"truth_rejection\"] = alluding_questions[\"truth_rejection\"]\n",
    "conversation[\"fiction_accepetance\"] = alluding_questions[\"fiction_accepetance\"]\n",
    "conversation[\"fiction_rejection\"] = alluding_questions[\"fiction_rejection\"]\n",
    "conversation.to_csv(question_path+'conversation.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
